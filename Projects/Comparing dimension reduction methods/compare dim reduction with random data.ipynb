{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a6b616-9ef2-4a97-8e42-dc72052c9220",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "I have a notebook for comparing the accuracy of a simple multi-category regression after the data dimension has been reduced using the following methods:\n",
    "\n",
    "- Nothing (use all dimensions)\n",
    "- Principal Components Analysis (PCA)\n",
    "- Multidimensional Scaling (MDS)\n",
    "- Kernel PCA with radial basis functions (Laplacian and Gaussian)\n",
    "- Isomap\n",
    "- Locally Linear Embedding (LLE)\n",
    "- Laplacian Eigenmaps (Spectral Embedding)\n",
    "- Hessian Eigenmaps\n",
    "- Local Tangent Space Alignment (LTSA)\n",
    "- Diffusion maps\n",
    "- Autoencoder\n",
    "- t-SNE (maybe)\n",
    "\n",
    "I used a sample of 1000 images from the MNIST dataset with all 10 classes. To compare the dimension reduction methods, I projected down to dimensions that are powers of two, arranged by order of magnitude: 2, 16, and 256. \n",
    "\n",
    "My new plan is to see what happens when I reduce the dimensions of completely random data. I'll reduce the dimensions of 1000 28x28 pixel images (with values sampled from a uniform distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652793ea-1358-47f5-9ccb-eeb3838636e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import MDS, LocallyLinearEmbedding, Isomap, SpectralEmbedding, TSNE\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "from kymatio.keras import Scattering2D\n",
    "import pyshearlab as ps\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b46acd-9dc6-486e-8e1a-1bb60a26caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name = None, input_shape = None):\n",
    "    \"\"\" Returns a Sequential model \"\"\"\n",
    "    \n",
    "    return Sequential(\n",
    "        [\n",
    "            Input(shape = (input_shape,)),\n",
    "            Dense(units = 10, activation = 'softmax', use_bias = False)\n",
    "        ],\n",
    "        name = name\n",
    "    )\n",
    "\n",
    "class DiffusionMap:\n",
    "    def __init__(self, alpha = 0.15, n_components = None):\n",
    "        self.alpha = alpha,\n",
    "        self.n_components = n_components\n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'DiffusionMap(alpha = {}, n_components = {})'.format(self.alpha, self.n_components)\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        \"\"\" Function to find the diffusion matrix P\n",
    "\n",
    "            args:\n",
    "            -----\n",
    "            alpha - to be used for gaussian kernel function\n",
    "            X - feature matrix as numpy array\n",
    "            n_components - number of lower dimensions\n",
    "\n",
    "            returns:\n",
    "            --------\n",
    "            Diffusion_map as np.array object\n",
    "        \"\"\"\n",
    "\n",
    "        dists = euclidean_distances(X, X)\n",
    "        K = np.exp(-dists**2 / self.alpha)\n",
    "\n",
    "        r = np.sum(K, axis = 0)\n",
    "        Di = np.diag(1/r)\n",
    "        P = np.matmul(Di, K)\n",
    "\n",
    "        D_right = np.diag((r)**0.5)\n",
    "        D_left = np.diag((r)**-0.5)\n",
    "        P_prime = np.matmul(D_right, np.matmul(P, D_left))\n",
    "\n",
    "        self.eigenValues, self.eigenVectors = eigh(P_prime)\n",
    "        idx = self.eigenValues.argsort()[::-1]\n",
    "        self.eigenValues = self.eigenValues[idx]\n",
    "        self.eigenVectors = self.eigenVectors[:, idx]\n",
    "\n",
    "        diffusion_coordinates = np.matmul(D_left, self.eigenVectors)\n",
    "        \n",
    "        self.diffusion_coordinates = diffusion_coordinates\n",
    "\n",
    "        return diffusion_coordinates[:, :self.n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4b672c-1bb8-4224-a1df-b3df8d8475e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimensionReduction:\n",
    "    \"\"\" General class to run several dimension reduction methods on a dataset \n",
    "        and then train and evaluate linear classifier on the transformed data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dim_reduction_names, X_train, y_train, X_test, y_test, n_components, n_neighbors = 7, gamma = 0.15, alpha = 0.15):\n",
    "        self.names = dim_reduction_names\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.n_components = n_components\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.n_neighbors_hessian = int((self.n_components * (self.n_components + 3))/2 + 1)\n",
    "        \n",
    "        # initialize with all dim reduction methods\n",
    "        all_methods = {\n",
    "            'pca': PCA(n_components = self.n_components),\n",
    "            'mds': MDS(n_components = self.n_components, max_iter = 20, n_init = 1),\n",
    "            'kpca_gaussian': KernelPCA(n_components = self.n_components, kernel = 'rbf', gamma = self.gamma),\n",
    "#             'kpca_laplacian': KernelPCA(n_components = self.n_components, kind = 'laplacian'), # 16SEPT - doesn't work yet\n",
    "            'lle': LocallyLinearEmbedding(n_components = self.n_components, method = 'standard'),\n",
    "            'isomap': Isomap(n_components = self.n_components, n_neighbors = self.n_neighbors),\n",
    "            'lap': SpectralEmbedding(n_components = self.n_components, n_neighbors = self.n_neighbors, gamma = self.gamma),\n",
    "            'hes': LocallyLinearEmbedding(n_components = self.n_components, n_neighbors = self.n_neighbors_hessian, method = 'hessian', eigen_solver = 'dense'),\n",
    "            'ltsa': LocallyLinearEmbedding(n_components = self.n_components, n_neighbors = self.n_components, method = 'ltsa'),\n",
    "            'diff': DiffusionMap(n_components = self.n_components, alpha = self.alpha)\n",
    "        }\n",
    "        \n",
    "        # select only the desired methods\n",
    "        self.methods = [all_methods[name] for name in self.names]\n",
    "        \n",
    "        print('Trial - Training linear classifier on data reduced to {} dimensions using the following methods:\\n{}'.format(self.n_components, self.names))\n",
    "        \n",
    "    def fit_dim_reduction(self):\n",
    "        \"\"\" Uses selected dim reduction methods to fit the dim reducing transformations \"\"\"\n",
    "        \n",
    "        self.X_train_reduced = [method.fit_transform(self.X_train) for method in self.methods]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def reduce_test_dimension(self):\n",
    "        \"\"\" Performs dim reduction on test data using fitted dim reduction methods \"\"\"\n",
    "        \n",
    "        self.X_test_reduced = [method.transform(self.X_test) for method in self.methods]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def build_classifiers(self):\n",
    "        \"\"\" Build a simple Sequential model for each dim reduction method \"\"\"\n",
    "        \n",
    "        self.models = [get_model(name, input_shape = self.n_components) for name, method in zip(self.names, self.methods)]\n",
    "        \n",
    "        for model in self.models:\n",
    "            model.compile(\n",
    "                loss = 'categorical_crossentropy',\n",
    "                optimizer = SGD(learning_rate = 0.01),\n",
    "                metrics = ['accuracy']\n",
    "            )\n",
    "        \n",
    "        print('All models built and compiled\\n')\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def train_classifiers(self):\n",
    "        \"\"\" Train all classifiers on the reduced dim training data \"\"\"\n",
    "        \n",
    "        self.training_accuracy = [\n",
    "            model.fit(\n",
    "                x,\n",
    "                self.y_train,\n",
    "                batch_size = 25,\n",
    "                epochs = 100,\n",
    "                verbose = False\n",
    "            ) for model, x in zip(self.models, self.X_train_reduced)\n",
    "        ]\n",
    "        \n",
    "        print('All models trained on reduced dim training data\\n')\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def test_classifiers(self):\n",
    "        \"\"\" Evaluate all classifiers on the reduced dim testing data \"\"\"\n",
    "        \n",
    "        self.test_accuracy = [\n",
    "            model.evaluate(\n",
    "                x = x,\n",
    "                y = self.y_test\n",
    "            ) for model, x in zip(self.models, self.X_test_reduced)\n",
    "        ]\n",
    "        \n",
    "        print('All models evaluated on reduced dim test data\\n')\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def get_model_accuracy(self):\n",
    "        \"\"\" Show the training and testing accuracy for all models \"\"\"\n",
    "        \n",
    "        headers = ['Method ({} dimensions)'.format(self.n_components), 'Training accuracy', 'Test accuracy']\n",
    "        \n",
    "        self.table = [\n",
    "            [name, train_result.history['accuracy'][-1]*100, test_result[-1]*100] for name, train_result, test_result in zip(self.names, self.training_accuracy, self.test_accuracy)\n",
    "        ]\n",
    "        \n",
    "        print(tabulate(self.table, headers = headers))\n",
    "        print('\\n{}\\n'.format('*'*100))\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\" Run through the set of experiments \"\"\"\n",
    "        \n",
    "        print('Initializing dimension reduction methods - reducing to d={}\\n'.format(self.n_components))\n",
    "        self.fit_dim_reduction()\n",
    "        self.reduce_test_dimension()\n",
    "        \n",
    "        print('Building classifier models for all dimension reduction methods')\n",
    "        self.build_classifiers()\n",
    "        \n",
    "        print('Training classifiers on reduced dimension training set')\n",
    "        self.train_classifiers()\n",
    "        \n",
    "        print('Testing classifiers on reduced dimension testing set')\n",
    "        self.test_classifiers()\n",
    "        \n",
    "        self.get_model_accuracy()\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc985a09-8cbf-4151-8b6c-844d09065059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used in Shearlet transform\n",
    "useGPU = True\n",
    "\n",
    "X = np.random.rand(1000, 784)\n",
    "X_test = np.random.rand(10000, 784)\n",
    "\n",
    "# randomly assign labels\n",
    "y = np.random.randint(low = 0, high = 10, size = 1000)\n",
    "y_test = np.random.randint(low = 0, high = 10, size = 10000)\n",
    "\n",
    "# encode the class labels as one-hot vectors\n",
    "y = to_categorical(y)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2240739-ad94-483a-98fd-f67a5a880595",
   "metadata": {},
   "source": [
    "# Classifier performance on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cfd7059-3cbd-41d1-8601-40741b8d54eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = get_model(name = 'full_model', input_shape = 784)\n",
    "full_model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = SGD(learning_rate = 0.01),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6e185f1-64a6-436e-a000-222cf5e41a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_full = full_model.fit(\n",
    "    X,\n",
    "    y,\n",
    "    batch_size = 25,\n",
    "    epochs = 50,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f643676c-eca9-4e6b-b1f3-f530ba922baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_model: 72.3000%\n"
     ]
    }
   ],
   "source": [
    "print('{}: {:.4f}%'.format(full_model.name, history_full.history['accuracy'][-1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eeae31-e793-4489-ae36-1fe3851eacc0",
   "metadata": {},
   "source": [
    "# Run trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e58d40f2-36ef-44c2-a37a-191b2abf0ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial - Training linear classifier on data reduced to 2 dimensions using the following methods:\n",
      "['pca', 'kpca_gaussian', 'lle', 'isomap', 'ltsa']\n",
      "Trial - Training linear classifier on data reduced to 16 dimensions using the following methods:\n",
      "['pca', 'kpca_gaussian', 'lle', 'isomap', 'ltsa']\n",
      "Trial - Training linear classifier on data reduced to 64 dimensions using the following methods:\n",
      "['pca', 'kpca_gaussian', 'lle', 'isomap', 'ltsa']\n",
      "Trial - Training linear classifier on data reduced to 256 dimensions using the following methods:\n",
      "['pca', 'kpca_gaussian', 'lle', 'isomap', 'ltsa']\n"
     ]
    }
   ],
   "source": [
    "names = ['pca', 'kpca_gaussian', 'lle', 'isomap', 'ltsa']\n",
    "\n",
    "trials = [\n",
    "    DimensionReduction(\n",
    "        names,\n",
    "        X_train = X,\n",
    "        y_train = y,\n",
    "        X_test = X_test,\n",
    "        y_test = y_test,\n",
    "        n_components = k\n",
    "    ) for k in [2, 16, 64, 256]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27e297af-33fa-4cea-b2ad-d24338cc56d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dimension reduction methods - reducing to d=2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py:937: LinAlgWarning: Diagonal number 1 is exactly zero. Singular matrix.\n",
      "  self.M_lu = lu_factor(M)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building classifier models for all dimension reduction methods\n",
      "All models built and compiled\n",
      "\n",
      "Training classifiers on reduced dimension training set\n",
      "All models trained on reduced dim training data\n",
      "\n",
      "Testing classifiers on reduced dimension testing set\n",
      "313/313 [==============================] - 0s 608us/step - loss: 2.3042 - accuracy: 0.1061\n",
      "313/313 [==============================] - 0s 594us/step - loss: 2.3026 - accuracy: 0.1011\n",
      "313/313 [==============================] - 0s 625us/step - loss: 2.3027 - accuracy: 0.0984\n",
      "313/313 [==============================] - 0s 641us/step - loss: 2.3111 - accuracy: 0.1051\n",
      "313/313 [==============================] - 0s 639us/step - loss: nan - accuracy: 0.1011\n",
      "All models evaluated on reduced dim test data\n",
      "\n",
      "Method (2 dimensions)      Training accuracy    Test accuracy\n",
      "-----------------------  -------------------  ---------------\n",
      "pca                                     12.5            10.61\n",
      "kpca_gaussian                            8.5            10.11\n",
      "lle                                     11.2             9.84\n",
      "isomap                                  12.1            10.51\n",
      "ltsa                                    10              10.11\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Initializing dimension reduction methods - reducing to d=16\n",
      "\n",
      "Building classifier models for all dimension reduction methods\n",
      "All models built and compiled\n",
      "\n",
      "Training classifiers on reduced dimension training set\n",
      "All models trained on reduced dim training data\n",
      "\n",
      "Testing classifiers on reduced dimension testing set\n",
      "313/313 [==============================] - 0s 630us/step - loss: 2.3159 - accuracy: 0.0984\n",
      "313/313 [==============================] - 0s 596us/step - loss: 2.3026 - accuracy: 0.1011\n",
      "313/313 [==============================] - 0s 564us/step - loss: 2.3027 - accuracy: 0.0995\n",
      "313/313 [==============================] - 0s 573us/step - loss: 2.3724 - accuracy: 0.0967\n",
      "313/313 [==============================] - 0s 678us/step - loss: 2.3027 - accuracy: 0.1004\n",
      "All models evaluated on reduced dim test data\n",
      "\n",
      "Method (16 dimensions)      Training accuracy    Test accuracy\n",
      "------------------------  -------------------  ---------------\n",
      "pca                                      15               9.84\n",
      "kpca_gaussian                            10.8            10.11\n",
      "lle                                      10.3             9.95\n",
      "isomap                                   13.5             9.67\n",
      "ltsa                                      9.9            10.04\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Initializing dimension reduction methods - reducing to d=64\n",
      "\n",
      "Building classifier models for all dimension reduction methods\n",
      "All models built and compiled\n",
      "\n",
      "Training classifiers on reduced dimension training set\n",
      "All models trained on reduced dim training data\n",
      "\n",
      "Testing classifiers on reduced dimension testing set\n",
      "313/313 [==============================] - 0s 610us/step - loss: 2.3451 - accuracy: 0.0994\n",
      "313/313 [==============================] - 0s 589us/step - loss: 2.3026 - accuracy: 0.1011\n",
      "313/313 [==============================] - 0s 613us/step - loss: 2.3029 - accuracy: 0.0969\n",
      "313/313 [==============================] - 0s 608us/step - loss: 2.6305 - accuracy: 0.0992\n",
      "313/313 [==============================] - 0s 612us/step - loss: 2.3027 - accuracy: 0.0966\n",
      "All models evaluated on reduced dim test data\n",
      "\n",
      "Method (64 dimensions)      Training accuracy    Test accuracy\n",
      "------------------------  -------------------  ---------------\n",
      "pca                                      25.6             9.94\n",
      "kpca_gaussian                            10.2            10.11\n",
      "lle                                      12.5             9.69\n",
      "isomap                                   21.2             9.92\n",
      "ltsa                                     10               9.66\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Initializing dimension reduction methods - reducing to d=256\n",
      "\n",
      "Building classifier models for all dimension reduction methods\n",
      "All models built and compiled\n",
      "\n",
      "Training classifiers on reduced dimension training set\n",
      "All models trained on reduced dim training data\n",
      "\n",
      "Testing classifiers on reduced dimension testing set\n",
      "313/313 [==============================] - 0s 604us/step - loss: 2.4607 - accuracy: 0.1005\n",
      "313/313 [==============================] - 0s 620us/step - loss: 2.3026 - accuracy: 0.1011\n",
      "313/313 [==============================] - 0s 619us/step - loss: 2.3026 - accuracy: 0.1029\n",
      "313/313 [==============================] - 0s 597us/step - loss: 7.8085 - accuracy: 0.0970\n",
      "313/313 [==============================] - 0s 634us/step - loss: 2.3027 - accuracy: 0.0961\n",
      "All models evaluated on reduced dim test data\n",
      "\n",
      "Method (256 dimensions)      Training accuracy    Test accuracy\n",
      "-------------------------  -------------------  ---------------\n",
      "pca                                       59              10.05\n",
      "kpca_gaussian                             14.3            10.11\n",
      "lle                                       13.3            10.29\n",
      "isomap                                    80.5             9.7\n",
      "ltsa                                      13.1             9.61\n",
      "\n",
      "****************************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for trial in trials:\n",
    "    trial.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c5b16-1bf1-4986-954d-9fc4044a9088",
   "metadata": {},
   "source": [
    "# Wavelet decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3fc4d4-f74c-469a-bbf6-7587f32ace66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fa6204dc170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to identify source code of lambda function <function <lambda> at 0x7fa6204dc170>. It was defined in this code:\n",
      "backend.fft = FFT(lambda x: tf.signal.fft2d(x, name='fft2d'),\n",
      "                  lambda x: tf.signal.ifft2d(x, name='ifft2d'),\n",
      "                  lambda x: tf.math.real(tf.signal.ifft2d(x, name='irfft2d')),\n",
      "                  lambda x: None)\n",
      "\n",
      "This code must contain a single distinguishable lambda. To avoid this problem, define each lambda in a separate expression.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fa6204dc170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to identify source code of lambda function <function <lambda> at 0x7fa6204dc170>. It was defined in this code:\n",
      "backend.fft = FFT(lambda x: tf.signal.fft2d(x, name='fft2d'),\n",
      "                  lambda x: tf.signal.ifft2d(x, name='ifft2d'),\n",
      "                  lambda x: tf.math.real(tf.signal.ifft2d(x, name='irfft2d')),\n",
      "                  lambda x: None)\n",
      "\n",
      "This code must contain a single distinguishable lambda. To avoid this problem, define each lambda in a separate expression.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (28, 28))\n",
    "x = Scattering2D(J = 4, L = 8)(inputs)\n",
    "x = Flatten()(x)\n",
    "x_out = Dense(10, activation = 'softmax')(x)\n",
    "model_scatter = Model(inputs, x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3ce5a50-8468-4b44-8242-f0d4d89fd411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "scattering2d (Scattering2D)  (None, 417, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 417)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                4180      \n",
      "=================================================================\n",
      "Total params: 4,180\n",
      "Trainable params: 4,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_scatter.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c71f46-31e7-4b33-b297-9a3f7171e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scatter.compile(\n",
    "        loss = 'categorical_crossentropy',\n",
    "        optimizer = SGD(learning_rate = 0.01),\n",
    "        metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddf4b6fa-58ed-4297-b5de-f7013c082e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scatter = np.array([img.reshape((28, 28)) for img in X])\n",
    "X_scatter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a2070e2-b304-47e2-95c9-b647576af332",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_scatter = model_scatter.fit(\n",
    "    X_scatter,\n",
    "    y,\n",
    "    batch_size = 25,\n",
    "    epochs = 50,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64d31684-1cf2-46a4-a1b5-272b23b57eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_scatter: 11.6000%\n"
     ]
    }
   ],
   "source": [
    "print('model_scatter: {:.4f}%'.format(history_scatter.history['accuracy'][-1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234a78e-3a3e-43b0-b387-1a88f57aa8d8",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "979242f6-e867-4c21-8090-a0254cc9bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder:\n",
    "    \n",
    "    def __init__(self, X, y, n_components):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_components = n_components\n",
    "        \n",
    "        # create the encoder and full autoencoder models\n",
    "        self.input_img = Input(shape = (784,))\n",
    "        \n",
    "        self.encoded = Dense(\n",
    "            self.n_components,\n",
    "            activation = 'relu'\n",
    "        )(self.input_img)\n",
    "        \n",
    "        self.decoded = Dense(\n",
    "            784,\n",
    "            activation = 'sigmoid'\n",
    "        )(self.encoded)\n",
    "        \n",
    "        self.autoencoder = Model(\n",
    "            self.input_img,\n",
    "            self.decoded\n",
    "        )\n",
    "        \n",
    "        self.encoder = Model(\n",
    "            self.input_img,\n",
    "            self.encoded\n",
    "        )\n",
    "        \n",
    "        # placeholder for encoded input\n",
    "        self.encoded_input = Input(\n",
    "            shape = (self.n_components,)\n",
    "        )\n",
    "        \n",
    "        # create decoder\n",
    "        self.decoder_layer = self.autoencoder.layers[-1]\n",
    "        self.decoder = Model(\n",
    "            self.encoded_input,\n",
    "            self.decoder_layer(self.encoded_input)\n",
    "        )\n",
    "        \n",
    "        # compile the autoencoder model\n",
    "        self.autoencoder.compile(\n",
    "            loss = 'categorical_crossentropy',\n",
    "            optimizer = SGD(learning_rate = 0.01),\n",
    "            metrics = ['accuracy']\n",
    "        )\n",
    "        \n",
    "    def fit(self):\n",
    "        self.autoencoder.fit(\n",
    "            self.X,\n",
    "            self.X,\n",
    "            epochs = 50,\n",
    "            batch_size = 25,\n",
    "            shuffle = True,\n",
    "            verbose = False\n",
    "        )\n",
    "        \n",
    "    def fit_transform(self):\n",
    "        return self.encoder.predict(self.X)\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.model = Sequential(\n",
    "            [\n",
    "                Input(shape = (self.n_components, )),\n",
    "                Dense(units = 10, activation = 'softmax', use_bias = False)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.model.compile(\n",
    "            loss = 'categorical_crossentropy',\n",
    "            optimizer = SGD(learning_rate = 0.01),\n",
    "            metrics = ['accuracy']\n",
    "        )\n",
    "        \n",
    "    def train_model(self):\n",
    "        reduced_dim = self.fit_transform()\n",
    "        self.history = self.model.fit(\n",
    "            reduced_dim,\n",
    "            self.y,\n",
    "            batch_size = 25,\n",
    "            epochs = 50,\n",
    "            verbose = False\n",
    "        )\n",
    "        \n",
    "        self.accuracy = self.history.history['accuracy'][-1]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c0deb-3893-477f-881c-9ab946d32fdc",
   "metadata": {},
   "source": [
    "## Autoencoder reducing to 2 dimensions\n",
    "\n",
    "Make an ensemble of 50 autoencoders, then take the average accuracy as the reported accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09fd6ee1-5f20-4620-a956-f2e199424da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "k = 2\n",
    "\n",
    "auto2 = [Autoencoder(X, y, k) for _ in range(N)]\n",
    "[a.fit() for a in auto2]\n",
    "\n",
    "[a.build_model() for a in auto2]\n",
    "[a.train_model() for a in auto2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dbf38ff-ab0a-4716-8eb3-c5449d14180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_autoencoder: 11.1000%\n",
      "model_autoencoder: 9.0000%\n",
      "model_autoencoder: 10.2000%\n",
      "model_autoencoder: 9.8000%\n",
      "model_autoencoder: 9.7000%\n",
      "model_autoencoder: 11.2000%\n",
      "model_autoencoder: 9.8000%\n",
      "model_autoencoder: 10.0000%\n",
      "model_autoencoder: 10.0000%\n",
      "model_autoencoder: 9.7000%\n",
      "model_autoencoder: 10.2000%\n",
      "model_autoencoder: 11.4000%\n",
      "model_autoencoder: 9.3000%\n",
      "model_autoencoder: 10.2000%\n",
      "model_autoencoder: 10.5000%\n",
      "model_autoencoder: 9.8000%\n",
      "model_autoencoder: 9.9000%\n",
      "model_autoencoder: 10.9000%\n",
      "model_autoencoder: 10.4000%\n",
      "model_autoencoder: 11.3000%\n",
      "model_autoencoder: 12.1000%\n",
      "model_autoencoder: 10.9000%\n",
      "model_autoencoder: 9.7000%\n",
      "model_autoencoder: 9.6000%\n",
      "model_autoencoder: 10.3000%\n",
      "model_autoencoder: 10.9000%\n",
      "model_autoencoder: 11.3000%\n",
      "model_autoencoder: 11.8000%\n",
      "model_autoencoder: 9.2000%\n",
      "model_autoencoder: 10.8000%\n",
      "model_autoencoder: 9.5000%\n",
      "model_autoencoder: 10.1000%\n",
      "model_autoencoder: 10.0000%\n",
      "model_autoencoder: 11.4000%\n",
      "model_autoencoder: 9.9000%\n",
      "model_autoencoder: 9.7000%\n",
      "model_autoencoder: 10.4000%\n",
      "model_autoencoder: 9.8000%\n",
      "model_autoencoder: 9.2000%\n",
      "model_autoencoder: 12.1000%\n",
      "model_autoencoder: 10.0000%\n",
      "model_autoencoder: 9.9000%\n",
      "model_autoencoder: 10.6000%\n",
      "model_autoencoder: 11.1000%\n",
      "model_autoencoder: 10.1000%\n",
      "model_autoencoder: 9.4000%\n",
      "model_autoencoder: 9.9000%\n",
      "model_autoencoder: 10.4000%\n",
      "model_autoencoder: 9.0000%\n",
      "model_autoencoder: 10.9000%\n",
      "Mean accuracy for 50 models: 10.288000017404556\n"
     ]
    }
   ],
   "source": [
    "for a in auto2:\n",
    "    print('model_autoencoder: {:.4f}%'.format(a.accuracy))\n",
    "          \n",
    "mean_accuracy2 = sum([a.accuracy for a in auto2])/N\n",
    "print('Mean accuracy for {} models: {}'.format(N, mean_accuracy2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c839fa5-4121-4884-b076-9c7374a949f1",
   "metadata": {},
   "source": [
    "## Autoencoder reducing to 16 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a7f4e73-796d-4778-b3fa-b6f0897316a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 16\n",
    "\n",
    "auto16 = [Autoencoder(X, y, k) for _ in range(N)]\n",
    "[a.fit() for a in auto16]\n",
    "\n",
    "[a.build_model() for a in auto16]\n",
    "[a.train_model() for a in auto16];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "734d5eae-09a7-4ced-84a2-e1db50af66a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_autoencoder: 11.5000%\n",
      "model_autoencoder: 11.4000%\n",
      "model_autoencoder: 11.6000%\n",
      "model_autoencoder: 11.3000%\n",
      "model_autoencoder: 13.1000%\n",
      "model_autoencoder: 12.3000%\n",
      "model_autoencoder: 11.5000%\n",
      "model_autoencoder: 11.1000%\n",
      "model_autoencoder: 11.5000%\n",
      "model_autoencoder: 9.8000%\n",
      "model_autoencoder: 11.7000%\n",
      "model_autoencoder: 12.4000%\n",
      "model_autoencoder: 11.6000%\n",
      "model_autoencoder: 10.5000%\n",
      "model_autoencoder: 9.7000%\n",
      "model_autoencoder: 9.6000%\n",
      "model_autoencoder: 12.8000%\n",
      "model_autoencoder: 10.8000%\n",
      "model_autoencoder: 10.7000%\n",
      "model_autoencoder: 12.1000%\n",
      "model_autoencoder: 12.3000%\n",
      "model_autoencoder: 11.6000%\n",
      "model_autoencoder: 12.6000%\n",
      "model_autoencoder: 11.4000%\n",
      "model_autoencoder: 12.1000%\n",
      "model_autoencoder: 11.7000%\n",
      "model_autoencoder: 11.5000%\n",
      "model_autoencoder: 12.1000%\n",
      "model_autoencoder: 11.9000%\n",
      "model_autoencoder: 12.1000%\n",
      "model_autoencoder: 13.3000%\n",
      "model_autoencoder: 11.9000%\n",
      "model_autoencoder: 9.7000%\n",
      "model_autoencoder: 10.4000%\n",
      "model_autoencoder: 13.5000%\n",
      "model_autoencoder: 10.9000%\n",
      "model_autoencoder: 10.8000%\n",
      "model_autoencoder: 9.5000%\n",
      "model_autoencoder: 13.9000%\n",
      "model_autoencoder: 13.2000%\n",
      "model_autoencoder: 11.8000%\n",
      "model_autoencoder: 12.2000%\n",
      "model_autoencoder: 12.0000%\n",
      "model_autoencoder: 12.4000%\n",
      "model_autoencoder: 11.4000%\n",
      "model_autoencoder: 11.6000%\n",
      "model_autoencoder: 13.1000%\n",
      "model_autoencoder: 10.9000%\n",
      "model_autoencoder: 12.0000%\n",
      "model_autoencoder: 11.0000%\n",
      "Mean accuracy for 50 models: 11.636000007390976\n"
     ]
    }
   ],
   "source": [
    "for a in auto16:\n",
    "    print('model_autoencoder: {:.4f}%'.format(a.accuracy))\n",
    "          \n",
    "mean_accuracy16 = sum([a.accuracy for a in auto16])/N\n",
    "print('Mean accuracy for {} models: {}'.format(N, mean_accuracy16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45186aa-c131-478a-b310-3830b7615266",
   "metadata": {},
   "source": [
    "## Autoencoder reducing to 256 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ff35d32-f65b-434c-9e7b-7b626c550b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 256\n",
    "\n",
    "auto256 = [Autoencoder(X, y, k) for _ in range(N)]\n",
    "[a.fit() for a in auto256]\n",
    "\n",
    "[a.build_model() for a in auto256]\n",
    "[a.train_model() for a in auto256];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b27998b-d889-4a4a-a2e4-d11f2fdfc3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_autoencoder: 30.7000%\n",
      "model_autoencoder: 28.7000%\n",
      "model_autoencoder: 29.6000%\n",
      "model_autoencoder: 29.5000%\n",
      "model_autoencoder: 29.6000%\n",
      "model_autoencoder: 30.4000%\n",
      "model_autoencoder: 26.7000%\n",
      "model_autoencoder: 29.4000%\n",
      "model_autoencoder: 29.2000%\n",
      "model_autoencoder: 30.2000%\n",
      "model_autoencoder: 25.8000%\n",
      "model_autoencoder: 27.6000%\n",
      "model_autoencoder: 28.7000%\n",
      "model_autoencoder: 28.4000%\n",
      "model_autoencoder: 28.2000%\n",
      "model_autoencoder: 26.9000%\n",
      "model_autoencoder: 26.1000%\n",
      "model_autoencoder: 27.3000%\n",
      "model_autoencoder: 28.0000%\n",
      "model_autoencoder: 27.9000%\n",
      "model_autoencoder: 30.3000%\n",
      "model_autoencoder: 26.5000%\n",
      "model_autoencoder: 25.3000%\n",
      "model_autoencoder: 27.3000%\n",
      "model_autoencoder: 29.0000%\n",
      "model_autoencoder: 26.9000%\n",
      "model_autoencoder: 29.1000%\n",
      "model_autoencoder: 26.4000%\n",
      "model_autoencoder: 29.0000%\n",
      "model_autoencoder: 28.5000%\n",
      "model_autoencoder: 26.7000%\n",
      "model_autoencoder: 29.5000%\n",
      "model_autoencoder: 26.0000%\n",
      "model_autoencoder: 27.4000%\n",
      "model_autoencoder: 27.7000%\n",
      "model_autoencoder: 30.6000%\n",
      "model_autoencoder: 29.7000%\n",
      "model_autoencoder: 27.0000%\n",
      "model_autoencoder: 27.8000%\n",
      "model_autoencoder: 25.0000%\n",
      "model_autoencoder: 29.5000%\n",
      "model_autoencoder: 26.1000%\n",
      "model_autoencoder: 28.5000%\n",
      "model_autoencoder: 26.4000%\n",
      "model_autoencoder: 29.4000%\n",
      "model_autoencoder: 29.0000%\n",
      "model_autoencoder: 30.4000%\n",
      "model_autoencoder: 27.7000%\n",
      "model_autoencoder: 27.6000%\n",
      "model_autoencoder: 29.8000%\n",
      "Mean accuracy for 50 models: 28.17999976873398\n"
     ]
    }
   ],
   "source": [
    "for a in auto256:\n",
    "    print('model_autoencoder: {:.4f}%'.format(a.accuracy))\n",
    "          \n",
    "mean_accuracy256 = sum([a.accuracy for a in auto256])/N\n",
    "print('Mean accuracy for {} models: {}'.format(N, mean_accuracy256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fff645-a266-4097-995a-bb70484be67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81beebcc-b7ed-49e3-9d8a-3b81ffec744a",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Ham, J., Lee, D. D., Mika, S., & Sch√∂lkopf, B. (2004, July). A kernel view of the dimensionality reduction of manifolds. In *Proceedings of the Twenty-First International Conference on Machine Learning* (p. 47)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
