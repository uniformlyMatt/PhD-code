{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a6b616-9ef2-4a97-8e42-dc72052c9220",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "To evaluate the usefulness of dimensionality reduction methods for digit classification. The methods to be evaluated are:\n",
    "\n",
    "- Nothing (use all dimensions)\n",
    "- Principal Components Analysis (PCA)\n",
    "- Multidimensional Scaling (MDS)\n",
    "- Kernel PCA with radial basis functions (Laplacian and Gaussian)\n",
    "- Isomap\n",
    "- Locally Linear Embedding (LLE)\n",
    "- Laplacian Eigenmaps (Spectral Embedding)\n",
    "- Hessian Eigenmaps\n",
    "- Local Tangent Space Alignment (LTSA)\n",
    "- Diffusion maps\n",
    "- Autoencoder\n",
    "- t-SNE (maybe)\n",
    "\n",
    "I'll use a sample of 1000 images from the MNIST dataset with all 10 classes. To compare the dimension reduction methods, I'll project down to dimensions that are powers of two, arranged by order of magnitude: 2, 64, and 256. The highest dimension (256) will therefore represent approximately 33% of the original dimensions (784) and the lowest dimension (2) will represent approximately 0.26% of the original dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "652793ea-1358-47f5-9ccb-eeb3838636e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import MDS, LocallyLinearEmbedding, Isomap, SpectralEmbedding, TSNE\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "from kymatio.keras import Scattering2D\n",
    "import pyshearlab as ps\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a50926a-fd8d-4612-96e9-a0594afb388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name = None, input_shape = None):\n",
    "    \"\"\" Returns a Sequential model \"\"\"\n",
    "    \n",
    "    return Sequential(\n",
    "        [\n",
    "            Input(shape = (input_shape,)),\n",
    "            Dense(units = 10, activation = 'softmax', use_bias = False)\n",
    "        ],\n",
    "        name = name\n",
    "    )\n",
    "\n",
    "class DiffusionMap:\n",
    "    def __init__(self, alpha = 0.15, n_components = None):\n",
    "        self.alpha = alpha,\n",
    "        self.n_components = n_components\n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'DiffusionMap(alpha = {}, n_components = {})'.format(self.alpha, self.n_components)\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        \"\"\" Function to find the diffusion matrix P\n",
    "\n",
    "            args:\n",
    "            -----\n",
    "            alpha - to be used for gaussian kernel function\n",
    "            X - feature matrix as numpy array\n",
    "            n_components - number of lower dimensions\n",
    "\n",
    "            returns:\n",
    "            --------\n",
    "            Diffusion_map as np.array object\n",
    "        \"\"\"\n",
    "\n",
    "        dists = euclidean_distances(X, X)\n",
    "        K = np.exp(-dists**2 / self.alpha)\n",
    "\n",
    "        r = np.sum(K, axis = 0)\n",
    "        Di = np.diag(1/r)\n",
    "        P = np.matmul(Di, K)\n",
    "\n",
    "        D_right = np.diag((r)**0.5)\n",
    "        D_left = np.diag((r)**-0.5)\n",
    "        P_prime = np.matmul(D_right, np.matmul(P, D_left))\n",
    "\n",
    "        self.eigenValues, self.eigenVectors = eigh(P_prime)\n",
    "        idx = self.eigenValues.argsort()[::-1]\n",
    "        self.eigenValues = self.eigenValues[idx]\n",
    "        self.eigenVectors = self.eigenVectors[:, idx]\n",
    "\n",
    "        diffusion_coordinates = np.matmul(D_left, self.eigenVectors)\n",
    "        \n",
    "        self.diffusion_coordinates = diffusion_coordinates\n",
    "\n",
    "        return diffusion_coordinates[:, :self.n_components]\n",
    "\n",
    "class DimensionReduction:\n",
    "    \"\"\" General class to run several dimension reduction methods on a dataset \n",
    "        and then train and evaluate linear classifier on the transformed data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dim_reduction_names, X_train, y_train, X_test, y_test, n_components, n_neighbors = 7, gamma = 0.15, alpha = 0.15):\n",
    "        self.names = dim_reduction_names\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.n_components = n_components\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.n_neighbors_hessian = int((self.n_components * (self.n_components + 3))/2 + 1)\n",
    "        \n",
    "        # initialize with all dim reduction methods\n",
    "        all_methods = {\n",
    "            'pca': PCA(n_components = self.n_components),\n",
    "            'mds': MDS(n_components = self.n_components, max_iter = 20, n_init = 1),\n",
    "            'kpca_gaussian': KernelPCA(n_components = self.n_components, kernel = 'rbf', gamma = self.gamma),\n",
    "#             'kpca_laplacian': KernelPCA(n_components = self.n_components, kind = 'laplacian'), # 16SEPT - doesn't work yet\n",
    "            'lle': LocallyLinearEmbedding(n_components = self.n_components, method = 'standard'),\n",
    "            'isomap': Isomap(n_components = self.n_components, n_neighbors = self.n_neighbors),\n",
    "            'lap': SpectralEmbedding(n_components = self.n_components, n_neighbors = self.n_neighbors, gamma = self.gamma),\n",
    "            'hes': LocallyLinearEmbedding(n_components = self.n_components, n_neighbors = self.n_neighbors_hessian, method = 'hessian', eigen_solver = 'dense'),\n",
    "            'ltsa': LocallyLinearEmbedding(n_components = self.n_components, n_neighbors = self.n_components, method = 'ltsa'),\n",
    "            'diff': DiffusionMap(n_components = self.n_components, alpha = self.alpha)\n",
    "        }\n",
    "        \n",
    "        # select only the desired methods\n",
    "        self.methods = [all_methods[name] for name in self.names]\n",
    "        \n",
    "        print('Trial - Training linear classifier on data reduced to {} dimensions using the following methods:\\n{}'.format(self.n_components, self.names))\n",
    "        \n",
    "    def fit_dim_reduction(self):\n",
    "        \"\"\" Uses selected dim reduction methods to fit the dim reducing transformations \"\"\"\n",
    "        \n",
    "        self.X_train_reduced = [method.fit_transform(self.X_train) for method in self.methods]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def reduce_test_dimension(self):\n",
    "        \"\"\" Performs dim reduction on test data using fitted dim reduction methods \"\"\"\n",
    "        \n",
    "        self.X_test_reduced = [method.transform(self.X_test) for method in self.methods]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def build_classifiers(self):\n",
    "        \"\"\" Build a simple Sequential model for each dim reduction method \"\"\"\n",
    "        \n",
    "        self.models = [get_model(name, input_shape = self.n_components) for name, method in zip(self.names, self.methods)]\n",
    "        \n",
    "        for model in self.models:\n",
    "            model.compile(\n",
    "                loss = 'categorical_crossentropy',\n",
    "                optimizer = SGD(learning_rate = 0.01),\n",
    "                metrics = ['accuracy']\n",
    "            )\n",
    "        \n",
    "        print('All models built and compiled\\n')\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def train_classifiers(self):\n",
    "        \"\"\" Train all classifiers on the reduced dim training data \"\"\"\n",
    "        \n",
    "        self.training_accuracy = [\n",
    "            model.fit(\n",
    "                x,\n",
    "                self.y_train,\n",
    "                batch_size = 25,\n",
    "                epochs = 100,\n",
    "                verbose = False\n",
    "            ) for model, x in zip(self.models, self.X_train_reduced)\n",
    "        ]\n",
    "        \n",
    "        print('All models trained on reduced dim training data\\n')\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def test_classifiers(self):\n",
    "        \"\"\" Evaluate all classifiers on the reduced dim testing data \"\"\"\n",
    "        \n",
    "        self.test_accuracy = [\n",
    "            model.evaluate(\n",
    "                x = x,\n",
    "                y = to_categorical(self.y_test)\n",
    "            ) for model, x in zip(self.models, self.X_test_reduced)\n",
    "        ]\n",
    "        \n",
    "        print('All models evaluated on reduced dim test data\\n')\n",
    "        \n",
    "        print('Generating predictions...\\n')\n",
    "        \n",
    "        self.predictions = [model.predict(x) for model, x in zip(self.models, self.X_test_reduced)]\n",
    "        self.predictions_boolean = [np.argmax(y, axis = 1) for y in self.predictions]\n",
    "        \n",
    "        for name, pred in zip(self.names, self.predictions_boolean):\n",
    "            print('Summary report for model: {}'.format(name))\n",
    "            print(classification_report(self.y_test, pred))\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def get_model_accuracy(self):\n",
    "        \"\"\" Show the training and testing accuracy for all models \"\"\"\n",
    "        \n",
    "        headers = ['Method ({} dimensions)'.format(self.n_components), 'Training accuracy', 'Test accuracy']\n",
    "        \n",
    "        self.table = [\n",
    "            [name, train_result.history['accuracy'][-1]*100, test_result[-1]*100] for name, train_result, test_result in zip(self.names, self.training_accuracy, self.test_accuracy)\n",
    "        ]\n",
    "        \n",
    "        print(tabulate(self.table, headers = headers))\n",
    "        print('\\n{}\\n'.format('*'*100))\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\" Run through the set of experiments \"\"\"\n",
    "        \n",
    "        print('Initializing dimension reduction methods - reducing to d={}\\n'.format(self.n_components))\n",
    "        self.fit_dim_reduction()\n",
    "        self.reduce_test_dimension()\n",
    "        \n",
    "        print('Building classifier models for all dimension reduction methods')\n",
    "        self.build_classifiers()\n",
    "        \n",
    "        print('Training classifiers on reduced dimension training set')\n",
    "        self.train_classifiers()\n",
    "        \n",
    "        print('Testing classifiers on reduced dimension testing set')\n",
    "        self.test_classifiers()\n",
    "        \n",
    "        self.get_model_accuracy()\n",
    "        \n",
    "        return None\n",
    "\n",
    "# used in Shearlet transform\n",
    "useGPU = True\n",
    "\n",
    "# names of dim reduction methods\n",
    "# names = ['pca', 'mds', 'kpca', 'lle', 'isomap', 'lap', 'ltsa', 'diff']\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# only do this for grayscale images\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "\n",
    "# get a random subsample of training data - helps speed up dim reduction\n",
    "N = 1000\n",
    "\n",
    "random_indices = np.random.randint(\n",
    "    0,\n",
    "    high = X_train.shape[0], \n",
    "    size = N\n",
    ")\n",
    "\n",
    "X = X_train[random_indices, :]\n",
    "y = y_train[random_indices]\n",
    "\n",
    "# encode the class labels as one-hot vectors\n",
    "y = to_categorical(y)\n",
    "y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4848624c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 784), numpy.ndarray)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "635370b6-020a-4411-b54d-ba4262f2e097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial - Training linear classifier on data reduced to 2 dimensions using the following methods:\n",
      "['pca', 'kpca_gaussian', 'lle', 'isomap', 'ltsa']\n",
      "Trial - Training linear classifier on data reduced to 16 dimensions using the following methods:\n",
      "['pca', 'kpca_gaussian', 'lle', 'isomap', 'ltsa']\n",
      "Trial - Training linear classifier on data reduced to 64 dimensions using the following methods:\n",
      "['pca', 'kpca_gaussian', 'lle', 'isomap', 'ltsa']\n",
      "Trial - Training linear classifier on data reduced to 256 dimensions using the following methods:\n",
      "['pca', 'kpca_gaussian', 'lle', 'isomap', 'ltsa']\n"
     ]
    }
   ],
   "source": [
    "names = ['pca', 'kpca_gaussian', 'lle', 'isomap', 'ltsa']\n",
    "\n",
    "trials = [\n",
    "    DimensionReduction(\n",
    "        names,\n",
    "        X_train = X,\n",
    "        y_train = y,\n",
    "        X_test = X_test,\n",
    "        y_test = y_test,\n",
    "        n_components = k\n",
    "    ) for k in [2, 16, 64, 256]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98cc232c-dc7b-4daa-9c6b-1af642ea95c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dimension reduction methods - reducing to d=2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py:937: LinAlgWarning: Diagonal number 9 is exactly zero. Singular matrix.\n",
      "  self.M_lu = lu_factor(M)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building classifier models for all dimension reduction methods\n",
      "All models built and compiled\n",
      "\n",
      "Training classifiers on reduced dimension training set\n",
      "All models trained on reduced dim training data\n",
      "\n",
      "Testing classifiers on reduced dimension testing set\n",
      "313/313 [==============================] - 0s 585us/step - loss: 1.5891 - accuracy: 0.3702\n",
      "313/313 [==============================] - 0s 585us/step - loss: 2.2990 - accuracy: 0.1010\n",
      "313/313 [==============================] - 0s 562us/step - loss: 2.2930 - accuracy: 0.1931\n",
      "313/313 [==============================] - 0s 566us/step - loss: 1.5040 - accuracy: 0.4132\n",
      "313/313 [==============================] - 0s 560us/step - loss: nan - accuracy: 0.0980\n",
      "All models evaluated on reduced dim test data\n",
      "\n",
      "Generating predictions...\n",
      "\n",
      "Summary report for model: pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.94      0.54       980\n",
      "           1       0.46      0.99      0.63      1135\n",
      "           2       0.33      0.24      0.28      1032\n",
      "           3       0.41      0.35      0.38      1010\n",
      "           4       0.30      0.29      0.29       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.30      0.74      0.43      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.37     10000\n",
      "   macro avg       0.22      0.36      0.26     10000\n",
      "weighted avg       0.23      0.37      0.26     10000\n",
      "\n",
      "Summary report for model: kpca_gaussian\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       980\n",
      "           1       0.00      0.00      0.00      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.11      1.00      0.20      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.00      0.00      0.00      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "Summary report for model: lle\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       980\n",
      "           1       0.00      0.00      0.00      1135\n",
      "           2       0.13      0.74      0.22      1032\n",
      "           3       0.04      0.01      0.02      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.24      0.19      0.21       892\n",
      "           6       0.48      0.96      0.64       958\n",
      "           7       0.29      0.06      0.11      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.01      0.01      0.01      1009\n",
      "\n",
      "    accuracy                           0.19     10000\n",
      "   macro avg       0.12      0.20      0.12     10000\n",
      "weighted avg       0.12      0.19      0.12     10000\n",
      "\n",
      "Summary report for model: isomap\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.96      0.61       980\n",
      "           1       0.54      0.54      0.54      1135\n",
      "           2       0.35      0.60      0.44      1032\n",
      "           3       0.43      0.57      0.49      1010\n",
      "           4       0.39      0.60      0.47       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.37      0.77      0.50      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.41     10000\n",
      "   macro avg       0.25      0.40      0.31     10000\n",
      "weighted avg       0.26      0.41      0.31     10000\n",
      "\n",
      "Summary report for model: ltsa\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      1.00      0.18       980\n",
      "           1       0.00      0.00      0.00      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.00      0.00      0.00      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.00      0.00      0.00      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "Method (2 dimensions)      Training accuracy    Test accuracy\n",
      "-----------------------  -------------------  ---------------\n",
      "pca                                     37.7            37.02\n",
      "kpca_gaussian                           10.9            10.1\n",
      "lle                                     20.1            19.31\n",
      "isomap                                  40.6            41.32\n",
      "ltsa                                    10.4             9.8\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Initializing dimension reduction methods - reducing to d=16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matt/anaconda3/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building classifier models for all dimension reduction methods\n",
      "All models built and compiled\n",
      "\n",
      "Training classifiers on reduced dimension training set\n",
      "All models trained on reduced dim training data\n",
      "\n",
      "Testing classifiers on reduced dimension testing set\n",
      "313/313 [==============================] - 0s 571us/step - loss: 0.5795 - accuracy: 0.8227\n",
      "313/313 [==============================] - 0s 627us/step - loss: 2.2943 - accuracy: 0.1276\n",
      "313/313 [==============================] - 0s 545us/step - loss: 2.2961 - accuracy: 0.1629\n",
      "313/313 [==============================] - 0s 616us/step - loss: 0.5878 - accuracy: 0.8403\n",
      "313/313 [==============================] - 0s 625us/step - loss: 2.2865 - accuracy: 0.3128\n",
      "All models evaluated on reduced dim test data\n",
      "\n",
      "Generating predictions...\n",
      "\n",
      "Summary report for model: pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       980\n",
      "           1       0.81      0.97      0.89      1135\n",
      "           2       0.85      0.77      0.81      1032\n",
      "           3       0.79      0.83      0.81      1010\n",
      "           4       0.85      0.79      0.82       982\n",
      "           5       0.81      0.65      0.72       892\n",
      "           6       0.82      0.87      0.84       958\n",
      "           7       0.83      0.85      0.84      1028\n",
      "           8       0.85      0.71      0.78       974\n",
      "           9       0.76      0.78      0.77      1009\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n",
      "Summary report for model: kpca_gaussian\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      1.00      0.21       980\n",
      "           1       1.00      0.24      0.38      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.06      0.01      0.02      1010\n",
      "           4       0.01      0.00      0.00       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.10      0.01      0.02       958\n",
      "           7       0.01      0.00      0.00      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.12      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.13     10000\n",
      "   macro avg       0.14      0.13      0.06     10000\n",
      "weighted avg       0.15      0.13      0.07     10000\n",
      "\n",
      "Summary report for model: lle\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.02      0.02       980\n",
      "           1       0.39      0.39      0.39      1135\n",
      "           2       0.42      0.69      0.52      1032\n",
      "           3       0.02      0.02      0.02      1010\n",
      "           4       0.66      0.32      0.43       982\n",
      "           5       0.02      0.03      0.02       892\n",
      "           6       0.01      0.01      0.01       958\n",
      "           7       0.00      0.00      0.00      1028\n",
      "           8       0.07      0.02      0.04       974\n",
      "           9       0.04      0.04      0.04      1009\n",
      "\n",
      "    accuracy                           0.16     10000\n",
      "   macro avg       0.16      0.16      0.15     10000\n",
      "weighted avg       0.17      0.16      0.16     10000\n",
      "\n",
      "Summary report for model: isomap\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       980\n",
      "           1       0.78      0.99      0.87      1135\n",
      "           2       0.90      0.78      0.83      1032\n",
      "           3       0.84      0.82      0.83      1010\n",
      "           4       0.86      0.75      0.80       982\n",
      "           5       0.84      0.71      0.77       892\n",
      "           6       0.88      0.94      0.91       958\n",
      "           7       0.85      0.87      0.86      1028\n",
      "           8       0.86      0.75      0.80       974\n",
      "           9       0.73      0.82      0.77      1009\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.85      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "Summary report for model: ltsa\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28       980\n",
      "           1       0.34      0.21      0.26      1135\n",
      "           2       0.03      0.01      0.01      1032\n",
      "           3       0.41      0.46      0.43      1010\n",
      "           4       0.56      0.32      0.41       982\n",
      "           5       0.02      0.02      0.02       892\n",
      "           6       0.65      0.38      0.48       958\n",
      "           7       0.43      0.52      0.47      1028\n",
      "           8       0.31      0.36      0.33       974\n",
      "           9       0.56      0.31      0.40      1009\n",
      "\n",
      "    accuracy                           0.31     10000\n",
      "   macro avg       0.35      0.31      0.31     10000\n",
      "weighted avg       0.35      0.31      0.31     10000\n",
      "\n",
      "Method (16 dimensions)      Training accuracy    Test accuracy\n",
      "------------------------  -------------------  ---------------\n",
      "pca                                      86.1            82.27\n",
      "kpca_gaussian                            13.6            12.76\n",
      "lle                                      15.2            16.29\n",
      "isomap                                   89.3            84.03\n",
      "ltsa                                     36.5            31.28\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Initializing dimension reduction methods - reducing to d=64\n",
      "\n",
      "Building classifier models for all dimension reduction methods\n",
      "All models built and compiled\n",
      "\n",
      "Training classifiers on reduced dimension training set\n",
      "All models trained on reduced dim training data\n",
      "\n",
      "Testing classifiers on reduced dimension testing set\n",
      "313/313 [==============================] - 0s 508us/step - loss: 0.4840 - accuracy: 0.8566\n",
      "313/313 [==============================] - 0s 521us/step - loss: 2.2877 - accuracy: 0.2092\n",
      "313/313 [==============================] - 0s 595us/step - loss: 2.2774 - accuracy: 0.3310\n",
      "313/313 [==============================] - 0s 597us/step - loss: 0.6656 - accuracy: 0.8542\n",
      "313/313 [==============================] - 0s 554us/step - loss: 2.2858 - accuracy: 0.1988\n",
      "All models evaluated on reduced dim test data\n",
      "\n",
      "Generating predictions...\n",
      "\n",
      "Summary report for model: pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       980\n",
      "           1       0.88      0.97      0.92      1135\n",
      "           2       0.89      0.82      0.86      1032\n",
      "           3       0.85      0.85      0.85      1010\n",
      "           4       0.86      0.80      0.83       982\n",
      "           5       0.85      0.76      0.80       892\n",
      "           6       0.85      0.92      0.88       958\n",
      "           7       0.85      0.89      0.87      1028\n",
      "           8       0.86      0.75      0.80       974\n",
      "           9       0.78      0.83      0.80      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "Summary report for model: kpca_gaussian\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       980\n",
      "           1       0.99      0.56      0.71      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.11      0.06      0.07      1010\n",
      "           4       0.30      0.27      0.28       982\n",
      "           5       0.13      1.00      0.23       892\n",
      "           6       0.31      0.11      0.17       958\n",
      "           7       0.12      0.01      0.01      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.51      0.13      0.20      1009\n",
      "\n",
      "    accuracy                           0.21     10000\n",
      "   macro avg       0.25      0.21      0.17     10000\n",
      "weighted avg       0.26      0.21      0.17     10000\n",
      "\n",
      "Summary report for model: lle\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.50      0.46       980\n",
      "           1       0.57      0.49      0.53      1135\n",
      "           2       0.43      0.60      0.50      1032\n",
      "           3       0.47      0.58      0.52      1010\n",
      "           4       0.07      0.06      0.06       982\n",
      "           5       0.06      0.07      0.06       892\n",
      "           6       0.11      0.09      0.10       958\n",
      "           7       0.32      0.36      0.34      1028\n",
      "           8       0.35      0.31      0.33       974\n",
      "           9       0.34      0.19      0.24      1009\n",
      "\n",
      "    accuracy                           0.33     10000\n",
      "   macro avg       0.32      0.32      0.31     10000\n",
      "weighted avg       0.32      0.33      0.32     10000\n",
      "\n",
      "Summary report for model: isomap\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       980\n",
      "           1       0.83      0.99      0.91      1135\n",
      "           2       0.89      0.83      0.86      1032\n",
      "           3       0.86      0.81      0.83      1010\n",
      "           4       0.85      0.75      0.80       982\n",
      "           5       0.84      0.81      0.82       892\n",
      "           6       0.90      0.93      0.91       958\n",
      "           7       0.87      0.88      0.87      1028\n",
      "           8       0.89      0.73      0.80       974\n",
      "           9       0.72      0.84      0.78      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "Summary report for model: ltsa\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.15      0.15       980\n",
      "           1       0.21      0.19      0.20      1135\n",
      "           2       0.21      0.21      0.21      1032\n",
      "           3       0.22      0.22      0.22      1010\n",
      "           4       0.11      0.11      0.11       982\n",
      "           5       0.18      0.31      0.23       892\n",
      "           6       0.37      0.36      0.36       958\n",
      "           7       0.20      0.15      0.17      1028\n",
      "           8       0.24      0.22      0.23       974\n",
      "           9       0.11      0.09      0.10      1009\n",
      "\n",
      "    accuracy                           0.20     10000\n",
      "   macro avg       0.20      0.20      0.20     10000\n",
      "weighted avg       0.20      0.20      0.20     10000\n",
      "\n",
      "Method (64 dimensions)      Training accuracy    Test accuracy\n",
      "------------------------  -------------------  ---------------\n",
      "pca                                      91.5            85.66\n",
      "kpca_gaussian                            26.5            20.92\n",
      "lle                                      29.9            33.1\n",
      "isomap                                   97.3            85.42\n",
      "ltsa                                     22.6            19.88\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Initializing dimension reduction methods - reducing to d=256\n",
      "\n",
      "Building classifier models for all dimension reduction methods\n",
      "All models built and compiled\n",
      "\n",
      "Training classifiers on reduced dimension training set\n",
      "All models trained on reduced dim training data\n",
      "\n",
      "Testing classifiers on reduced dimension testing set\n",
      "313/313 [==============================] - 0s 603us/step - loss: 0.4784 - accuracy: 0.8593\n",
      "313/313 [==============================] - 0s 608us/step - loss: 2.2901 - accuracy: 0.3174\n",
      "313/313 [==============================] - 0s 597us/step - loss: 2.2745 - accuracy: 0.3888\n",
      "313/313 [==============================] - 0s 608us/step - loss: 0.7097 - accuracy: 0.8504\n",
      "313/313 [==============================] - 0s 612us/step - loss: 2.2831 - accuracy: 0.3238\n",
      "All models evaluated on reduced dim test data\n",
      "\n",
      "Generating predictions...\n",
      "\n",
      "Summary report for model: pca\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       980\n",
      "           1       0.89      0.97      0.92      1135\n",
      "           2       0.90      0.83      0.86      1032\n",
      "           3       0.85      0.85      0.85      1010\n",
      "           4       0.88      0.81      0.84       982\n",
      "           5       0.85      0.76      0.80       892\n",
      "           6       0.87      0.91      0.89       958\n",
      "           7       0.83      0.88      0.85      1028\n",
      "           8       0.86      0.75      0.80       974\n",
      "           9       0.78      0.85      0.81      1009\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "Summary report for model: kpca_gaussian\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.13      0.19       980\n",
      "           1       0.99      0.79      0.88      1135\n",
      "           2       0.11      0.04      0.05      1032\n",
      "           3       0.20      0.02      0.04      1010\n",
      "           4       0.29      0.03      0.06       982\n",
      "           5       0.27      0.05      0.09       892\n",
      "           6       0.18      0.79      0.30       958\n",
      "           7       0.71      0.30      0.42      1028\n",
      "           8       0.22      0.36      0.27       974\n",
      "           9       0.32      0.59      0.42      1009\n",
      "\n",
      "    accuracy                           0.32     10000\n",
      "   macro avg       0.37      0.31      0.27     10000\n",
      "weighted avg       0.38      0.32      0.28     10000\n",
      "\n",
      "Summary report for model: lle\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.52      0.50       980\n",
      "           1       0.34      0.28      0.31      1135\n",
      "           2       0.35      0.33      0.34      1032\n",
      "           3       0.47      0.47      0.47      1010\n",
      "           4       0.37      0.40      0.38       982\n",
      "           5       0.33      0.27      0.30       892\n",
      "           6       0.45      0.57      0.51       958\n",
      "           7       0.44      0.43      0.44      1028\n",
      "           8       0.33      0.33      0.33       974\n",
      "           9       0.28      0.28      0.28      1009\n",
      "\n",
      "    accuracy                           0.39     10000\n",
      "   macro avg       0.38      0.39      0.39     10000\n",
      "weighted avg       0.38      0.39      0.39     10000\n",
      "\n",
      "Summary report for model: isomap\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       980\n",
      "           1       0.85      0.99      0.91      1135\n",
      "           2       0.92      0.81      0.86      1032\n",
      "           3       0.84      0.83      0.83      1010\n",
      "           4       0.85      0.75      0.80       982\n",
      "           5       0.84      0.80      0.82       892\n",
      "           6       0.90      0.91      0.91       958\n",
      "           7       0.85      0.88      0.87      1028\n",
      "           8       0.87      0.73      0.80       974\n",
      "           9       0.71      0.82      0.76      1009\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "Summary report for model: ltsa\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.26      0.29       980\n",
      "           1       0.46      0.50      0.48      1135\n",
      "           2       0.30      0.28      0.29      1032\n",
      "           3       0.21      0.21      0.21      1010\n",
      "           4       0.38      0.28      0.32       982\n",
      "           5       0.36      0.43      0.39       892\n",
      "           6       0.30      0.35      0.33       958\n",
      "           7       0.47      0.54      0.50      1028\n",
      "           8       0.16      0.17      0.17       974\n",
      "           9       0.22      0.19      0.20      1009\n",
      "\n",
      "    accuracy                           0.32     10000\n",
      "   macro avg       0.32      0.32      0.32     10000\n",
      "weighted avg       0.32      0.32      0.32     10000\n",
      "\n",
      "Method (256 dimensions)      Training accuracy    Test accuracy\n",
      "-------------------------  -------------------  ---------------\n",
      "pca                                       92.3            85.93\n",
      "kpca_gaussian                             28.1            31.74\n",
      "lle                                       29.5            38.88\n",
      "isomap                                   100              85.04\n",
      "ltsa                                      23.7            32.38\n",
      "\n",
      "****************************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for trial in trials:\n",
    "    trial.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2240739-ad94-483a-98fd-f67a5a880595",
   "metadata": {},
   "source": [
    "# Classifier performance on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfd7059-3cbd-41d1-8601-40741b8d54eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = get_model(name = 'full_model', input_shape = 784)\n",
    "full_model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = SGD(learning_rate = 0.01),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e185f1-64a6-436e-a000-222cf5e41a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_full = full_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 25,\n",
    "    epochs = 50,\n",
    "    verbose = False\n",
    ")\n",
    "\n",
    "test_full = full_model.evaluate(\n",
    "    x = X_test,\n",
    "    y = y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f643676c-eca9-4e6b-b1f3-f530ba922baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy\\n{}: {:.4f}%\\n'.format(full_model.name, history_full.history['accuracy'][-1]*100))\n",
    "print('Test accuracy\\n{}: {:.4f}%\\n'.format(full_model.name, test_full[-1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3257e-bd0a-4a8f-a05d-eae72a0a896e",
   "metadata": {},
   "source": [
    "# Let's check a classifier's performance on the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9575c3e-7975-494c-bf0b-af7933b8334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model = get_model(name = 'sample_model', input_shape = 784)\n",
    "sample_model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = SGD(learning_rate = 0.01),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5953b1-7478-42e9-86b7-cdbd3087e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_sample = sample_model.fit(\n",
    "    X,\n",
    "    y,\n",
    "    batch_size = 25,\n",
    "    epochs = 50,\n",
    "    verbose = False\n",
    ")\n",
    "\n",
    "test_sample = sample_model.evaluate(\n",
    "    x = X_test,\n",
    "    y = y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a681e2b-cd2f-4b1f-bc20-58a7306e7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy\\n{}: {:.4f}%\\n'.format(sample_model.name, history_sample.history['accuracy'][-1]*100))\n",
    "print('Test accuracy\\n{}: {:.4f}%\\n'.format(sample_model.name, test_sample[-1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c5b16-1bf1-4986-954d-9fc4044a9088",
   "metadata": {},
   "source": [
    "# Sept 2 - Wavelet decompositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a3fc4d4-f74c-469a-bbf6-7587f32ace66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f54005f8e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to identify source code of lambda function <function <lambda> at 0x7f54005f8e60>. It was defined in this code:\n",
      "backend.fft = FFT(lambda x: tf.signal.fft2d(x, name='fft2d'),\n",
      "                  lambda x: tf.signal.ifft2d(x, name='ifft2d'),\n",
      "                  lambda x: tf.math.real(tf.signal.ifft2d(x, name='irfft2d')),\n",
      "                  lambda x: None)\n",
      "\n",
      "This code must contain a single distinguishable lambda. To avoid this problem, define each lambda in a separate expression.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7f54005f8e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to identify source code of lambda function <function <lambda> at 0x7f54005f8e60>. It was defined in this code:\n",
      "backend.fft = FFT(lambda x: tf.signal.fft2d(x, name='fft2d'),\n",
      "                  lambda x: tf.signal.ifft2d(x, name='ifft2d'),\n",
      "                  lambda x: tf.math.real(tf.signal.ifft2d(x, name='irfft2d')),\n",
      "                  lambda x: None)\n",
      "\n",
      "This code must contain a single distinguishable lambda. To avoid this problem, define each lambda in a separate expression.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# wavelet decomposition\n",
    "inputs = Input(shape = (28, 28))\n",
    "x = Scattering2D(J = 3, L = 8)(inputs)\n",
    "x = Flatten()(x)\n",
    "x_out = Dense(10, activation = 'softmax')(x)\n",
    "model_scatter = Model(inputs, x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3ce5a50-8468-4b44-8242-f0d4d89fd411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_56 (InputLayer)        [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "scattering2d (Scattering2D)  (None, 217, 3, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1953)              0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 10)                19540     \n",
      "=================================================================\n",
      "Total params: 19,540\n",
      "Trainable params: 19,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_scatter.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2c71f46-31e7-4b33-b297-9a3f7171e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scatter.compile(\n",
    "        loss = 'categorical_crossentropy',\n",
    "        optimizer = SGD(learning_rate = 0.01),\n",
    "        metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddf4b6fa-58ed-4297-b5de-f7013c082e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scatter = np.array([img.reshape((28, 28)) for img in X])\n",
    "X_scatter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a2070e2-b304-47e2-95c9-b647576af332",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_scatter = model_scatter.fit(\n",
    "    X_scatter,\n",
    "    y,\n",
    "    batch_size = 25,\n",
    "    epochs = 50,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64d31684-1cf2-46a4-a1b5-272b23b57eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_scatter: 51.0000%\n"
     ]
    }
   ],
   "source": [
    "print('model_scatter: {:.4f}%'.format(history_scatter.history['accuracy'][-1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234a78e-3a3e-43b0-b387-1a88f57aa8d8",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979242f6-e867-4c21-8090-a0254cc9bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder:\n",
    "    \n",
    "    def __init__(self, X, y, n_components):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_components = n_components\n",
    "        \n",
    "        # create the encoder and full autoencoder models\n",
    "        self.input_img = Input(shape = (784,))\n",
    "        \n",
    "        self.encoded = Dense(\n",
    "            self.n_components,\n",
    "            activation = 'relu'\n",
    "        )(self.input_img)\n",
    "        \n",
    "        self.decoded = Dense(\n",
    "            784,\n",
    "            activation = 'sigmoid'\n",
    "        )(self.encoded)\n",
    "        \n",
    "        self.autoencoder = Model(\n",
    "            self.input_img,\n",
    "            self.decoded\n",
    "        )\n",
    "        \n",
    "        self.encoder = Model(\n",
    "            self.input_img,\n",
    "            self.encoded\n",
    "        )\n",
    "        \n",
    "        # placeholder for encoded input\n",
    "        self.encoded_input = Input(\n",
    "            shape = (self.n_components,)\n",
    "        )\n",
    "        \n",
    "        # create decoder\n",
    "        self.decoder_layer = self.autoencoder.layers[-1]\n",
    "        self.decoder = Model(\n",
    "            self.encoded_input,\n",
    "            self.decoder_layer(self.encoded_input)\n",
    "        )\n",
    "        \n",
    "        # compile the autoencoder model\n",
    "        self.autoencoder.compile(\n",
    "            loss = 'categorical_crossentropy',\n",
    "            optimizer = SGD(learning_rate = 0.01),\n",
    "            metrics = ['accuracy']\n",
    "        )\n",
    "        \n",
    "    def fit(self):\n",
    "        self.autoencoder.fit(\n",
    "            self.X,\n",
    "            self.X,\n",
    "            epochs = 50,\n",
    "            batch_size = 25,\n",
    "            shuffle = True,\n",
    "            verbose = False\n",
    "        )\n",
    "        \n",
    "    def fit_transform(self):\n",
    "        return self.encoder.predict(self.X)\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.model = Sequential(\n",
    "            [\n",
    "                Input(shape = (self.n_components, )),\n",
    "                Dense(units = 10, activation = 'softmax', use_bias = False)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.model.compile(\n",
    "            loss = 'categorical_crossentropy',\n",
    "            optimizer = SGD(learning_rate = 0.01),\n",
    "            metrics = ['accuracy']\n",
    "        )\n",
    "        \n",
    "    def train_model(self):\n",
    "        reduced_dim = self.fit_transform()\n",
    "        self.history = self.model.fit(\n",
    "            reduced_dim,\n",
    "            self.y,\n",
    "            batch_size = 25,\n",
    "            epochs = 50,\n",
    "            verbose = False\n",
    "        )\n",
    "        \n",
    "        self.accuracy = self.history.history['accuracy'][-1]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c0deb-3893-477f-881c-9ab946d32fdc",
   "metadata": {},
   "source": [
    "## Autoencoder reducing to 2 dimensions\n",
    "\n",
    "Make an ensemble of 50 autoencoders, then take the average accuracy as the reported accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd6ee1-5f20-4620-a956-f2e199424da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "k = 2\n",
    "\n",
    "auto2 = [Autoencoder(X, y, k) for _ in range(N)]\n",
    "[a.fit() for a in auto2]\n",
    "\n",
    "[a.build_model() for a in auto2]\n",
    "[a.train_model() for a in auto2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf38ff-ab0a-4716-8eb3-c5449d14180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in auto2:\n",
    "    print('model_autoencoder: {:.4f}%'.format(a.accuracy))\n",
    "          \n",
    "mean_accuracy2 = sum([a.accuracy for a in auto2])/N\n",
    "print('Mean accuracy for {} models: {}'.format(N, mean_accuracy2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c839fa5-4121-4884-b076-9c7374a949f1",
   "metadata": {},
   "source": [
    "## Autoencoder reducing to 16 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f4e73-796d-4778-b3fa-b6f0897316a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 16\n",
    "\n",
    "auto16 = [Autoencoder(X, y, k) for _ in range(N)]\n",
    "[a.fit() for a in auto16]\n",
    "\n",
    "[a.build_model() for a in auto16]\n",
    "[a.train_model() for a in auto16];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d5eae-09a7-4ced-84a2-e1db50af66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in auto16:\n",
    "    print('model_autoencoder: {:.4f}%'.format(a.accuracy))\n",
    "          \n",
    "mean_accuracy16 = sum([a.accuracy for a in auto16])/N\n",
    "print('Mean accuracy for {} models: {}'.format(N, mean_accuracy16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45186aa-c131-478a-b310-3830b7615266",
   "metadata": {},
   "source": [
    "## Autoencoder reducing to 256 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff35d32-f65b-434c-9e7b-7b626c550b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 256\n",
    "\n",
    "auto256 = [Autoencoder(X, y, k) for _ in range(N)]\n",
    "[a.fit() for a in auto256]\n",
    "\n",
    "[a.build_model() for a in auto256]\n",
    "[a.train_model() for a in auto256];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b27998b-d889-4a4a-a2e4-d11f2fdfc3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in auto256:\n",
    "    print('model_autoencoder: {:.4f}%'.format(a.accuracy))\n",
    "          \n",
    "mean_accuracy256 = sum([a.accuracy for a in auto256])/N\n",
    "print('Mean accuracy for {} models: {}'.format(N, mean_accuracy256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b6350-d866-41b5-8ac9-6f4583a3e18c",
   "metadata": {},
   "source": [
    "## Autoencoder reducing to 783 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fff645-a266-4097-995a-bb70484be67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 783\n",
    "\n",
    "auto783 = [Autoencoder(X, y, k) for _ in range(N)]\n",
    "[a.fit() for a in auto783]\n",
    "\n",
    "[a.build_model() for a in auto783]\n",
    "[a.train_model() for a in auto783];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6855d59-a69a-42d8-bd16-68efa1359e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in auto783:\n",
    "    print('model_autoencoder: {:.4f}%'.format(a.accuracy))\n",
    "          \n",
    "mean_accuracy783 = sum([a.accuracy for a in auto783])/N\n",
    "print('Mean accuracy for {} models: {}'.format(N, mean_accuracy783))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81beebcc-b7ed-49e3-9d8a-3b81ffec744a",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Ham, J., Lee, D. D., Mika, S., & Schlkopf, B. (2004, July). A kernel view of the dimensionality reduction of manifolds. In *Proceedings of the Twenty-First International Conference on Machine Learning* (p. 47)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7580af449b29ae74e232076340076da0d1f5e5729b86173641c6c8b128833ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
